{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import utilities\n",
    "import os\n",
    "import sys\n",
    "import Shapelet_from_UCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_binary = ['BeetleFly','BirdChicken','Coffee','Computers','DistalPhalanxOutlineCorrect','Earthquakes','ECG200',\n",
    "                   'ECGFiveDays','FordA','FordB','GunPoint','Ham','HandOutlines','Herring','ItalyPowerDemand','Lightning2',\n",
    "                   'MiddlePhalanxOutlineCorrect', 'MoteStrain','PhalangesOutlinesCorrect','ProximalPhalanxOutlineCorrect',\n",
    "                   'ShapeletSim','SonyAIBORobotSurface1','SonyAIBORobotSurface2','Strawberry','ToeSegmentation1','ToeSegmentation2',\n",
    "                   'TwoLeadECG','Wafer','Wine','WormsTwoClass','Yoga','Chinatown','DodgerLoopGame','DodgerLoopWeekend',\n",
    "                   'FreezerRegularTrain','FreezerSmallTrain','GunPointAgeSpan','GunPointMaleVersusFemale','GunPointOldVersusYoung',\n",
    "                   'HouseTwenty','PowerCons','SemgHandGenderCh2']\n",
    "datasets_small = ['BeetleFly', 'BirdChicken', 'Coffee', 'Computers', 'DistalPhalanxOutlineCorrect', 'Earthquakes', 'ECG200', \n",
    "                  'ECGFiveDays', 'GunPoint', 'Ham', 'Herring', 'Lightning2', 'MiddlePhalanxOutlineCorrect', 'ProximalPhalanxOutlineCorrect', \n",
    "                  'ShapeletSim', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'Strawberry', 'ToeSegmentation1', 'ToeSegmentation2', 'Wine', \n",
    "                  'WormsTwoClass', 'Chinatown', 'DodgerLoopGame', 'DodgerLoopWeekend', 'GunPointAgeSpan', 'GunPointMaleVersusFemale', \n",
    "                  'GunPointOldVersusYoung', 'HouseTwenty', 'PowerCons', 'SemgHandGenderCh2']\n",
    "dataset_large=['FordA', 'FordB', 'HandOutlines', 'ItalyPowerDemand', 'MoteStrain', 'PhalangesOutlinesCorrect', \n",
    "               'TwoLeadECG', 'Wafer', 'Yoga', 'FreezerRegularTrain', 'FreezerSmallTrain']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import paired_distances\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "from itertools import repeat\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_distance(S,T):\n",
    "    \n",
    "    if S.all()==None or T.all()==None:\n",
    "        return np.inf\n",
    "    assert isinstance(S,np.ndarray)\n",
    "    assert isinstance(T,np.ndarray) \n",
    "    assert isinstance(S[0],float)\n",
    "    assert isinstance(T[0],float)\n",
    "    \n",
    "    if len(S)>len(T):\n",
    "        aux_S=T\n",
    "        T=S\n",
    "        S=aux_S\n",
    "    \n",
    "    dist_list=[]\n",
    "    m=len(T)\n",
    "    w=len(S)\n",
    "        \n",
    "    for i in range(m-w+1):\n",
    "        dist=np.linalg.norm(T[i:i+w]-S)\n",
    "        dist_list.append(dist)\n",
    "    return min(dist_list)\n",
    "def dist_vectorize(T,shapelets):\n",
    "    # check shapelets is a 2d array\n",
    "    assert isinstance(shapelets,np.ndarray)\n",
    "    assert isinstance(shapelets[0],np.ndarray)\n",
    "    #assert isinstance(shapelets[0][0],float)\n",
    "    \n",
    "    # check T is a 1d array\n",
    "    assert isinstance(T,np.ndarray)\n",
    "    assert isinstance(T[0], float)\n",
    "    \n",
    "    dist_list=[]\n",
    "    m=len(T)\n",
    "    w=len(shapelets[0])\n",
    "    subsequences=subsequences1d(T,w) \n",
    "    #print(subsequences)\n",
    "    dist_mat=distance.cdist(shapelets,subsequences)\n",
    "    \n",
    "    return dist_mat.min(axis=1)\n",
    "\n",
    "\n",
    "def subsequences1d(arr, m=None):\n",
    "    assert isinstance(arr,np.ndarray)\n",
    "    assert isinstance(arr[0],float)\n",
    "    \n",
    "    if m==None:\n",
    "        m=int(np.log(arr.shape[0]+1))+1\n",
    "    n = arr.shape[0] - m + 1\n",
    "    s = arr.itemsize\n",
    "    #print(m,arr.shape[0])\n",
    "    return np.lib.stride_tricks.as_strided(arr, shape=(n,m), strides=(s,s))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min subsequence distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K(T1,T2)=K_s(vectorise(T1,S), VECTORIZE(T2,S))=(v1-v2)^2\n",
    "def min_sub_distance(T1,T2,k=None):\n",
    "    #T1,T2 should be lists of subsequences\n",
    "    S1=subsequences1d(T1,k)\n",
    "    S2=subsequences1d(T2,k)\n",
    "    assert isinstance(S1,np.ndarray)\n",
    "    assert isinstance(S2,np.ndarray) \n",
    "    assert isinstance(S1[0],np.ndarray)\n",
    "    assert isinstance(S2[0],np.ndarray)\n",
    "    assert isinstance(S1[0][0],float)\n",
    "    assert isinstance(S2[0][0],float)\n",
    "    \n",
    "    #union\n",
    "    S=np.unique(np.concatenate((S1,S2), axis=0),axis=0)\n",
    "    \n",
    "   \n",
    "    v1=dist_vectorize(T1,S)\n",
    "    v2=dist_vectorize(T2,S)\n",
    "    \n",
    "    return np.linalg.norm(v1-v2, ord=2)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minimum shapelet distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_shapelet_distance(T1,T2,shapelets,k=None):\n",
    "    \n",
    "    assert isinstance(T1,np.ndarray)\n",
    "    assert isinstance(T2,np.ndarray) \n",
    "    assert isinstance(T1[0],float)\n",
    "    assert isinstance(T2[0],float)\n",
    "    assert isinstance(shapelets,np.ndarray)\n",
    "    assert isinstance(shapelets[0],np.ndarray)\n",
    "    #assert isinstance(shapelets[0][0],float)\n",
    "    \n",
    "    #calculate the distance vector where each element is min_dist between shapelet and T\n",
    "    \n",
    "    V1=dist_vectorize(T1,shapelets)\n",
    "    V2=dist_vectorize(T2,shapelets)\n",
    "    \n",
    "    \n",
    "    return np.linalg.norm(V1-V2, ord=2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from scipy.stats import uniform\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_random_search_cv(train_dataset,train_label, param_grid,shapelet_grid, X, y, cv=5):\n",
    "    # Stratified K-fold\n",
    "    cv = StratifiedKFold(n_splits=cv, shuffle=False)\n",
    "    results = []\n",
    "    #combine parameters at random: length & number & K(neighbour)\n",
    "    w=shapelet_grid['length']\n",
    "    n=shapelet_grid['number']\n",
    "    k=param_grid['K']\n",
    "    C=random.sample(list(itertools.product(w,n,k)),10)\n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        split_results = []\n",
    "        params = [] \n",
    "        for idx, comb in enumerate(C):\n",
    "            print('comb:',comb)\n",
    "            #####Should the shapelets be extracted from entire datasets or splitted training sets?#####\n",
    "            shapelets = Shapelet_from_UCR.Shapelet_random(train_dataset, train_label,length=int(comb[0]),number_search=1000,top_number=comb[1])\n",
    "            shapelets=np.asarray(shapelets)\n",
    "            print('extracted shapelets')\n",
    "            clf = KNeighborsClassifier(n_neighbors=comb[2],metric=min_shapelet_distance,metric_params={'shapelets':shapelets})\n",
    "            clf.fit(train_dataset[train_index],train_label[train_index])\n",
    "            sc=clf.score(train_dataset[test_index],train_label[test_index])        \n",
    "            split_results.append(sc)\n",
    "            params.append({'idx': idx, 'params': comb})\n",
    "        results.append(split_results)\n",
    "    # Collect results and average\n",
    "    results = np.array(results)\n",
    "    fin_results = results.mean(axis=0)\n",
    "    # select the best results\n",
    "    best_idx = np.argmax(fin_results)\n",
    "    # Return the fitted model and the best_parameters\n",
    "    best_shapelets=Shapelet_from_UCR.Shapelet_random(train_dataset, train_label,length=int(params[best_idx]['params'][0]),number_search=1000,top_number=params[best_idx]['params'][1])\n",
    "    best_model=KNeighborsClassifier(n_neighbors=params[best_idx]['params'][2],metric=min_shapelet_distance,metric_params={'shapelets':best_shapelets})\n",
    "    \n",
    "    return best_model.fit(X, y), params[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "comb: (10.0, 70, 4)\n"
     ]
    }
   ],
   "source": [
    "#test for one dataset\n",
    "dataset_list=[]\n",
    "auroc_list=[]\n",
    "auprc_list=[]\n",
    "param_list=[]\n",
    "for dataset in datasets_small[:1]:\n",
    "    X_train, y_train, X_test, y_test = utilities.get_ucr_dataset('../UCRArchive_2018/',dataset)\n",
    "    L=len(X_train[0])\n",
    "    print(L)######L=max length of time series for this datasets?#####\n",
    "    shapelet_grid={'length':np.logspace(np.log10(2),np.log10(np.log2(L)+1),num=5),'number':range(10,100)}\n",
    "    model_grid={'K':range(2,6)}\n",
    "    best_model,best_para=customized_random_search_cv(X_train,y_train, model_grid,shapelet_grid, X_train, y_train, cv=5)\n",
    "    print(best_para)\n",
    "    \n",
    "    y_pred = best_model.predict_proba(X_test)\n",
    "    auroc=roc_auc_score(y_test, y_pred[:, 1])\n",
    "    auprc=average_precision_score(y_test, y_pred[:,1])\n",
    "    print(dataset, \" AUROC is: \", auroc,\" AUPRC is: \", auprc)\n",
    "    dataset_list.append(dataset)\n",
    "    auroc_list.append(auroc)\n",
    "    auprc_list.append(auprc)\n",
    "    param_list.append(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid search\n",
    "#### change later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e1906967804a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'metric_params'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ucr_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../UCRArchive_2018/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpairwise_min_shapelet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets_small' is not defined"
     ]
    }
   ],
   "source": [
    "#Grid Search over datasets, subsequence length as a hyper-parameter \n",
    "dataset_list=[]\n",
    "auroc_list=[]\n",
    "auprc_list=[]\n",
    "param_list=[]\n",
    "parameters = {'n_neighbors':[1],'metric_params':[{'k':1},{'k':2},{'k':3},{'k':4}]}\n",
    "\n",
    "for dataset in datasets_small[:1]:\n",
    "    X_train, y_train, X_test, y_test = utilities.get_ucr_dataset('../UCRArchive_2018/',dataset)\n",
    "    clf = GridSearchCV(KNeighborsClassifier(metric=pairwise_min_shapelet),parameters, cv=5, verbose=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #get best estimator\n",
    "    print(clf.best_params_)\n",
    "    opt_clf=clf.best_estimator_\n",
    "    \n",
    "    y_pred = opt_clf.predict_proba(X_test)\n",
    "    \n",
    "    auroc=roc_auc_score(y_test, y_pred[:, 1])\n",
    "    auprc=average_precision_score(y_test, y_pred[:,1])\n",
    "    print(dataset, \" AUROC is: \", auroc,\" AUPRC is: \", auprc)\n",
    "    dataset_list.append(dataset)\n",
    "    auroc_list.append(auroc)\n",
    "    auprc_list.append(auprc)\n",
    "    param_list.append(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('pairwise_min_shapelet_KNN.csv', [p for p in zip(dataset_list, auroc_list,auprc_list,param_list)], delimiter=',',fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "V1=np.array([0,0,1,2])\n",
    "V2=np.array([3,4,0,0])\n",
    "v3=np.array([1,2,0,0])\n",
    "v4=np.array([0,0,3,4])\n",
    "a=np.linalg.norm(V1-V2, ord=2)\n",
    "b=np.linalg.norm(v3-v4, ord=2)\n",
    "print(a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
